{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.99)\n",
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: comtypes in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.13)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Downloading speechrecognition-3.14.4-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/32.9 MB 4.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.6/32.9 MB 3.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/32.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.4/32.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 4.7/32.9 MB 4.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.5/32.9 MB 4.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.6/32.9 MB 4.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 7.9/32.9 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 9.2/32.9 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 10.7/32.9 MB 5.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 12.3/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 13.4/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 14.7/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 15.7/32.9 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 16.5/32.9 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 17.0/32.9 MB 5.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 17.6/32.9 MB 5.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 18.6/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 19.7/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 21.0/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 21.8/32.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 23.1/32.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 24.4/32.9 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 26.0/32.9 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 27.3/32.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 28.0/32.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 28.8/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 29.6/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 30.9/32.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 31.7/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.5/32.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 4.9 MB/s  0:00:06\n",
      "Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio, SpeechRecognition\n",
      "\n",
      "   -------------------- ------------------- 1/2 [SpeechRecognition]\n",
      "   -------------------- ------------------- 1/2 [SpeechRecognition]\n",
      "   ---------------------------------------- 2/2 [SpeechRecognition]\n",
      "\n",
      "Successfully installed SpeechRecognition-3.14.4 pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil requests pyttsx3 SpeechRecognition pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipwin\n",
      "  Downloading pipwin-0.5.2.tar.gz (7.9 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting docopt (from pipwin)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (2.32.3)\n",
      "Collecting pyprind (from pipwin)\n",
      "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (4.12.3)\n",
      "Collecting js2py (from pipwin)\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Requirement already satisfied: packaging in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (24.1)\n",
      "Collecting pySmartDL>=1.3.1 (from pipwin)\n",
      "  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.9.0->pipwin) (2.5)\n",
      "Collecting tzlocal>=1.2 (from js2py->pipwin)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pyjsparser>=2.5.1 (from js2py->pipwin)\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tzdata in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from tzlocal>=1.2->js2py->pipwin) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (2024.8.30)\n",
      "Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
      "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.1 MB/s  0:00:00\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Building wheels for collected packages: pipwin, docopt, pyjsparser\n",
      "  Building wheel for pipwin (pyproject.toml): started\n",
      "  Building wheel for pipwin (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pipwin: filename=pipwin-0.5.2-py2.py3-none-any.whl size=8874 sha256=f6317c38f05d7ee5ad91ee50b2745ab33d0bae62b5cffd6c3d6a1267e4812ade\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\e8\\b5\\1d\\b94f69a230c016fe50ed36399dec48b34b82a11e4f344e9ccb\n",
      "  Building wheel for docopt (pyproject.toml): started\n",
      "  Building wheel for docopt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13858 sha256=f7c68d1b1eb50e3a0f62088a1061c4cabf088f48927ca6bbc5aaef5302d20522\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for pyjsparser (pyproject.toml): started\n",
      "  Building wheel for pyjsparser (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=26014 sha256=aef97d513ad63c0900ac569becf96203126800e45a2cf0c2623a47da078d4a55\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\14\\32\\1d\\9ef7b582e358446aeef4b9052aa89ef4dffa1688c1aae8aa13\n",
      "Successfully built pipwin docopt pyjsparser\n",
      "Installing collected packages: pySmartDL, pyprind, pyjsparser, docopt, tzlocal, js2py, pipwin\n",
      "\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------------------- 7/7 [pipwin]\n",
      "\n",
      "Successfully installed docopt-0.6.2 js2py-0.74 pipwin-0.5.2 pySmartDL-1.3.4 pyjsparser-2.7.1 pyprind-2.11.3 tzlocal-5.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\P R VISHAL\\anaconda3\\Scripts\\pipwin.exe\\__main__.py\", line 2, in <module>\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\pipwin\\command.py\", line 28, in <module>\n",
      "    from . import pipwin, __version__\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\pipwin\\pipwin.py\", line 13, in <module>\n",
      "    import js2py\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\__init__.py\", line 72, in <module>\n",
      "    from .base import PyJsException\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 2965, in <module>\n",
      "    @Js\n",
      "     ^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 165, in Js\n",
      "    return PyJsFunction(val, FunctionPrototype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 1377, in __init__\n",
      "    cand = fix_js_args(func)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\utils\\injector.py\", line 27, in fix_js_args\n",
      "    code = append_arguments(six.get_function_code(func), ('this', 'arguments'))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\utils\\injector.py\", line 121, in append_arguments\n",
      "    arg = name_translations[inst.arg]\n",
      "          ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 3\n"
     ]
    }
   ],
   "source": [
    "!pip install pipwin\n",
    "!pipwin install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic>=2.9->ollama)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 621.2 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 780.2 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 762.0 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 762.0 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.3/2.0 MB 729.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 729.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 662.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 681.9 kB/s  0:00:02\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, typing-inspection, pydantic-core, pydantic, ollama\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "  Attempting uninstall: pydantic-core\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "  Attempting uninstall: pydantic\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   -------------------------------- ------- 4/5 [ollama]\n",
      "   ---------------------------------------- 5/5 [ollama]\n",
      "\n",
      "Successfully installed ollama-0.6.1 pydantic-2.12.5 pydantic-core-2.41.5 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama psutil requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama psutil requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIDAY: Authentication required.\n",
      "FRIDAY: Access granted. FRIDAY online.\n",
      "FRIDAY: Autonomous multi-stage agentic cognition online.\n",
      "FRIDAY: Intent identified as OPEN_APP\n",
      "FRIDAY: Analyzing user objective\n",
      "FRIDAY: Reasoning through the problem\n",
      "FRIDAY: Here's the step-by-step reasoning for the user command \"open notepad+chrome+whatsapp\":\n",
      "\n",
      "1. **Tokenization**: Break down the command into individual tokens:\n",
      "\t* Token 1: \"open\"\n",
      "\t* Token 2: \"notepad\"\n",
      "\t* Token 3: \"+\"\n",
      "\t* Token 4: \"chrome\"\n",
      "\t* Token 5: \"+\"\n",
      "\t* Token 6: \"whatsapp\"\n",
      "\n",
      "2. **Parser**: Analyze the tokens to determine their meaning and relationships:\n",
      "\t* Token 1 (\"open\") is a command verb, indicating that the user wants to perform an action (in this case, opening an application).\n",
      "\t* Tokens 2-3 (\"notepad+\") form a compound token, where \"notepad\" is likely the name of an application or file type, and the \"+\" sign indicates that it should be opened.\n",
      "\t* Token 4 (\"chrome\") is probably another application or program to be opened.\n",
      "\t* Tokens 5-6 (\"+whatsapp\") also form a compound token, where \"+whatsapp\" could mean opening WhatsApp (possibly in a specific context, like \"open WhatsApp\").\n",
      "\n",
      "3. **Semantic Analysis**: Interpret the meaning of each token and their relationships:\n",
      "\t* The user wants to open three applications: Notepad, Chrome, and WhatsApp.\n",
      "\t* There is no direct implication that these applications should be opened simultaneously or in a specific order.\n",
      "\n",
      "4. **Action Plan**: Determine the steps needed to execute the command:\n",
      "\t1. Open Notepad ( Token 2-3).\n",
      "\t2. Open Chrome (Token 4).\n",
      "\t3. Open WhatsApp (Tokens 5-6).\n",
      "\n",
      "The final result would be opening these three applications, likely in separate windows or tabs.\n",
      "\n",
      "Note: Depending on the specific operating system and desktop environment, the command might need additional processing to handle things like window management or file associations.\n",
      "FRIDAY: Selecting best available knowledge source\n",
      "FRIDAY: Goal → task decomposition\n",
      "FRIDAY: Sub-task dependency handling (DAG)\n",
      "FRIDAY: Preparing fallback strategy if needed\n",
      "FRIDAY: Action → Outcome → Evaluation loop\n",
      "FRIDAY: Self-driven execution\n",
      "FRIDAY: Executing sub-task 1: open notepad+chrome+whatsapp\n",
      "FRIDAY: {\n",
      "  \"1\": \"Notepad opened\\nChrome opened\\nWhatsapp opened\"\n",
      "}\n",
      "FRIDAY: Command mode activated.\n",
      "FRIDAY: HIIIII Bro! How's life been treating you lately?\n",
      "FRIDAY: An **interview** is a conversation between two people: the interviewer (who asks questions) and the interviewee (who answers them). The purpose of an interview is to gather information, assess qualifications, and make informed decisions.\n",
      "\n",
      "In simple terms, an interview is like a chat with someone who wants to learn more about you, your skills, experiences, and fit for a particular role or opportunity. It's a chance for both parties to get to know each other better and determine if it's a good match.\n",
      "\n",
      "Interviews can take many forms, such as:\n",
      "\n",
      "* Face-to-face interviews: In-person conversations with one or multiple interviewers.\n",
      "* Phone or video interviews: Remote conversations via phone or video conferencing tools like Zoom or Skype.\n",
      "* Screening interviews: Initial, brief conversations to narrow down candidates and identify the best fit.\n",
      "\n",
      "Common types of interviews include:\n",
      "\n",
      "* Initial screening interview: A brief introduction to get a sense of your background and interests.\n",
      "* Behavioral interview: Questions that focus on specific scenarios or behaviors you've demonstrated in the past.\n",
      "* Technical interview: In-depth discussions about technical skills, expertise, and problem-solving abilities.\n",
      "\n",
      "That's it! An interview is just a conversation where both parties want to learn more about each other.\n",
      "FRIDAY: I cannot provide information or guidance on illegal or harmful activities, including hacking into someone else's WiFi network.\n",
      "FRIDAY: Document received.\n",
      "FRIDAY: I'm happy to help!\n",
      "\n",
      "However, I need a bit more information from you.\n",
      "\n",
      "Can you please share the following details about the document:\n",
      "\n",
      "1. **File type**: Is it a PDF, Word document (.docx), Excel file (.xlsx), or something else?\n",
      "2. **Size**: Approximately how many pages or kilobytes is the document?\n",
      "3. **Purpose**: What's the purpose of the document? (e.g., report, proposal, resume)\n",
      "4. **Content**: Can you give me a brief summary of what the document contains?\n",
      "\n",
      "Once I have this information, I can try to help you understand what's inside the document.\n",
      "\n",
      "Remember to keep your questions and responses concise, as it will help me provide more accurate assistance!\n",
      "FRIDAY: A `.txt` file!\n",
      "\n",
      "By default, a `.txt` file contains plain text data, which means it's just a collection of characters without any formatting or structure.\n",
      "\n",
      "Here are some possible contents you might find inside a `.txt` file:\n",
      "\n",
      "1. **Plain text**: A simple text document containing paragraphs, sentences, or individual words.\n",
      "2. **Code snippets**: Short pieces of code written in programming languages like Python, Java, or C++.\n",
      "3. **Notes or reminders**: Quick jottings or to-do lists for personal use.\n",
      "4. **Transcripts or logs**: Recordings of conversations, meetings, or system logs.\n",
      "\n",
      "If you're curious about the contents of your `.txt` file, feel free to share more details or ask me specific questions!\n",
      "\n",
      "Remember, I'm here to help and provide guidance, not to pry into sensitive information.\n",
      "FRIDAY: Command mode deactivated.\n",
      "FRIDAY: Intent identified as BATTERY_STATUS\n",
      "FRIDAY: Analyzing user objective\n",
      "FRIDAY: Reasoning through the problem\n",
      "FRIDAY: Here's the step-by-step reasoning for interpreting the user command \"battery status\":\n",
      "\n",
      "1. **Tokenization**: The command is broken down into individual words or tokens.\n",
      "\n",
      "Command: battery status\n",
      "Tokens: [battery, status]\n",
      "\n",
      "2. **Command Identification**: Each token is examined to identify the main action being requested (i.e., the command).\n",
      "\n",
      "* \"battery\" is likely an object or entity of interest.\n",
      "* \"status\" is a verb indicating that the user wants information about the battery.\n",
      "\n",
      "3. **Command Classification**: The identified command is classified into a specific category or domain.\n",
      "\n",
      "* This command falls under the category of \"System Information\" or \"Device Status\".\n",
      "\n",
      "4. **Action Determination**: The intent behind the command is determined.\n",
      "\n",
      "* The user wants to know the current status of their battery, which could include information such as charge level, remaining capacity, charging state (e.g., plugged in, charging, or fully charged), and any potential issues or errors.\n",
      "\n",
      "5. **Query Generation**: Based on the identified command and intent, a query is generated to retrieve the necessary information from a data source (e.g., a database, API, or device).\n",
      "\n",
      "* The query might be: \"What is the current status of the battery?\" or \"Get the charge level, capacity, and charging state of the battery.\"\n",
      "\n",
      "6. **Response Generation**: The retrieved information is used to generate a response to the user.\n",
      "\n",
      "* This could include a formatted display of the battery's status, such as:\n",
      "\t+ \"Battery Status: 80% charged, fully charged.\"\n",
      "\t+ \"Battery Status: Charging (50%), expected full charge in 30 minutes.\"\n",
      "\n",
      "7. **Output Generation**: The generated response is formatted and output to the user.\n",
      "\n",
      "* The final output might be a text-based or graphical representation of the battery's status, depending on the interface being used (e.g., command-line, GUI, or voice assistant).\n",
      "\n",
      "By following this step-by-step reasoning process, the system can effectively interpret the user command \"battery status\" and provide the desired information to the user.\n",
      "FRIDAY: Selecting best available knowledge source\n",
      "FRIDAY: Goal → task decomposition\n",
      "FRIDAY: Sub-task dependency handling (DAG)\n",
      "FRIDAY: Preparing fallback strategy if needed\n",
      "FRIDAY: Action → Outcome → Evaluation loop\n",
      "FRIDAY: Self-driven execution\n",
      "FRIDAY: Executing sub-task 1: battery status\n",
      "FRIDAY: {\n",
      "  \"1\": \"Battery: 99% (charging). Unlimited\"\n",
      "}\n",
      "FRIDAY: Shutting down. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import threading\n",
    "import webbrowser\n",
    "import time\n",
    "import urllib.parse\n",
    "import psutil\n",
    "import requests\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext, messagebox\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import pyttsx3\n",
    "except ImportError:\n",
    "    pyttsx3 = None\n",
    "\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except ImportError:\n",
    "    sr = None\n",
    "\n",
    "try:\n",
    "    import pvporcupine\n",
    "    from pvrecorder import PvRecorder\n",
    "except ImportError:\n",
    "    pvporcupine = None\n",
    "    PvRecorder = None\n",
    "\n",
    "try:\n",
    "    import ollama\n",
    "except ImportError:\n",
    "    ollama = None\n",
    "\n",
    "try:\n",
    "    import PyPDF2\n",
    "except ImportError:\n",
    "    PyPDF2 = None\n",
    "\n",
    "try:\n",
    "    from docx import Document\n",
    "except ImportError:\n",
    "    Document = None\n",
    "\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    BeautifulSoup = None\n",
    "\n",
    "try:\n",
    "    from duckduckgo_search import DDGS\n",
    "except ImportError:\n",
    "    DDGS = None\n",
    "\n",
    "# ==================================================\n",
    "# CONFIGURATION\n",
    "# ==================================================\n",
    "BASE_FOLDER = r\"C:\\Users\\P R VISHAL\\OneDrive\\Desktop\\FRIDAY..!!\"\n",
    "\n",
    "if not os.path.exists(BASE_FOLDER):\n",
    "    os.makedirs(BASE_FOLDER)\n",
    "    print(f\"[INFO] Created folder: {BASE_FOLDER}\")\n",
    "\n",
    "MEMORY_FILE = os.path.join(BASE_FOLDER, \"friday_memory.json\")\n",
    "NOTES_FILE = os.path.join(BASE_FOLDER, \"friday_notes.txt\")\n",
    "LAST_COMMANDS_FILE = os.path.join(BASE_FOLDER, \"friday_last_commands.txt\")\n",
    "\n",
    "PASSWORD = \"1234\"\n",
    "ACCESS_KEY = \"\"\n",
    "WAKE_WORD_PATH = \"\"\n",
    "\n",
    "# ==================================================\n",
    "# VOICE ENGINE\n",
    "# ==================================================\n",
    "class VoiceEngine:\n",
    "    def __init__(self):\n",
    "        self.enabled = pyttsx3 is not None\n",
    "        self.lock = threading.Lock()\n",
    "        if self.enabled:\n",
    "            self.engine = pyttsx3.init(driverName=\"sapi5\")\n",
    "            self.engine.setProperty(\"rate\", 165)\n",
    "            self.engine.setProperty(\"volume\", 1.0)\n",
    "            self.engine.say(\" \")\n",
    "            self.engine.runAndWait()\n",
    "\n",
    "    def speak(self, text):\n",
    "        print(\"FRIDAY:\", text)\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        with self.lock:\n",
    "            try:\n",
    "                self.engine.stop()\n",
    "                self.engine.say(text)\n",
    "                self.engine.runAndWait()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def listen_once(self):\n",
    "        if sr is None:\n",
    "            print(\"Speech recognition not available.\")\n",
    "            return \"\"\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            self.speak(\"Listening...\")\n",
    "            try:\n",
    "                audio = r.listen(source, timeout=5, phrase_time_limit=10)\n",
    "            except sr.WaitTimeoutError:\n",
    "                return \"\"\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"You (voice):\", text)\n",
    "            return text.lower()\n",
    "        except:\n",
    "            self.speak(\"I could not understand.\")\n",
    "            return \"\"\n",
    "\n",
    "    def continuous_listen(self):\n",
    "        if pvporcupine and ACCESS_KEY and WAKE_WORD_PATH:\n",
    "            try:\n",
    "                porcupine = pvporcupine.create(access_key=ACCESS_KEY, keyword_paths=[WAKE_WORD_PATH])\n",
    "                recorder = PvRecorder(frame_length=porcupine.frame_length)\n",
    "                recorder.start()\n",
    "                self.speak(\"Continuous listening activated. Say 'Hey Friday'\")\n",
    "                while True:\n",
    "                    pcm = recorder.read()\n",
    "                    if porcupine.process(pcm) >= 0:\n",
    "                        self.speak(\"Yes sir?\")\n",
    "                        cmd = self.listen_once()\n",
    "                        recorder.stop()\n",
    "                        porcupine.delete()\n",
    "                        recorder.delete()\n",
    "                        return cmd or \"\"\n",
    "            except Exception as e:\n",
    "                pass  # Silent fail\n",
    "\n",
    "        self.speak(\"Wake word not configured. Using manual trigger.\")\n",
    "        return self.listen_once()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# MEMORY ENGINE - SAFE & AUTO-CREATE\n",
    "# ==================================================\n",
    "class MemoryEngine:\n",
    "    def __init__(self):\n",
    "        self.default_structure = {\n",
    "            \"short\": [],\n",
    "            \"long\": [],\n",
    "            \"context\": {\n",
    "                \"last_action\": \"\",\n",
    "                \"last_topic\": \"\",\n",
    "                \"last_search\": \"\"\n",
    "            },\n",
    "            \"chatbot_history\": []\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(MEMORY_FILE):\n",
    "            self.data = self.default_structure.copy()\n",
    "            self.save()\n",
    "            print(f\"[INFO] Created new memory file: {MEMORY_FILE}\")\n",
    "        else:\n",
    "            try:\n",
    "                self.load()\n",
    "                self.validate_and_fix()\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Memory file issue: {e}. Creating fresh one.\")\n",
    "                self.data = self.default_structure.copy()\n",
    "                self.save()\n",
    "\n",
    "        if not os.path.exists(NOTES_FILE):\n",
    "            with open(NOTES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"# FRIDAY Research Notes\\n\\n\")\n",
    "        if not os.path.exists(LAST_COMMANDS_FILE):\n",
    "            with open(LAST_COMMANDS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"# Recent Commands Log\\n\\n\")\n",
    "\n",
    "    def load(self):\n",
    "        with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def save(self):\n",
    "        with open(MEMORY_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.data, f, indent=2)\n",
    "\n",
    "    def validate_and_fix(self):\n",
    "        for key in self.default_structure:\n",
    "            if key not in self.data:\n",
    "                self.data[key] = self.default_structure[key]\n",
    "        if \"context\" not in self.data or not isinstance(self.data[\"context\"], dict):\n",
    "            self.data[\"context\"] = self.default_structure[\"context\"]\n",
    "        if not isinstance(self.data[\"short\"], list):\n",
    "            self.data[\"short\"] = []\n",
    "        if not isinstance(self.data[\"long\"], list):\n",
    "            self.data[\"long\"] = []\n",
    "        if \"chatbot_history\" not in self.data or not isinstance(self.data[\"chatbot_history\"], list):\n",
    "            self.data[\"chatbot_history\"] = []\n",
    "        self.save()\n",
    "\n",
    "    def update_context(self, key, value):\n",
    "        self.data[\"context\"][key] = value\n",
    "        self.save()\n",
    "\n",
    "    def get_context(self, key):\n",
    "        return self.data[\"context\"].get(key, \"\")\n",
    "\n",
    "    def get_recent_commands(self, n=6):\n",
    "        commands = []\n",
    "        for i in range(len(self.data[\"short\"]) - 1, -1, -2):\n",
    "            if i < len(self.data[\"short\"]) and self.data[\"short\"][i][\"role\"] == \"user\":\n",
    "                commands.append(self.data[\"short\"][i][\"content\"])\n",
    "            if len(commands) >= n:\n",
    "                break\n",
    "        return commands[::-1]\n",
    "\n",
    "    def store_conversation(self, user, assistant):\n",
    "        self.data[\"short\"].append({\"role\": \"user\", \"content\": user})\n",
    "        self.data[\"short\"].append({\"role\": \"assistant\", \"content\": assistant})\n",
    "        if len(self.data[\"short\"]) > 30:\n",
    "            self.data[\"long\"].extend(self.data[\"short\"][:10])\n",
    "            self.data[\"short\"] = self.data[\"short\"][10:]\n",
    "        self.save()\n",
    "\n",
    "        with open(LAST_COMMANDS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | You: {user}\\n\")\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | FRIDAY: {assistant}\\n\\n\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# INTENT ENGINE (LLM + CONFIDENCE + EXPLANATION)\n",
    "# ==================================================\n",
    "class IntentEngine:\n",
    "    def analyze(self, text, history, context):\n",
    "        fused_context = f\"Recent history: {json.dumps(history[-5:])}\\nContext: {json.dumps(context)}\\nSystem: CPU {psutil.cpu_percent(interval=0.1)}%, RAM {psutil.virtual_memory().percent}%\"\n",
    "        if ollama:\n",
    "            prompt = f\"\"\"\n",
    "Analyze the user's intent for this command: \"{text}\"\n",
    "Context: {fused_context}\n",
    "Output only JSON:\n",
    "{{\n",
    "  \"intent\": \"OPEN_APP\" or \"PLAY_YOUTUBE\" or \"BATTERY_STATUS\" etc.,\n",
    "  \"params\": {{...}},\n",
    "  \"confidence\": 0.0 to 1.0,\n",
    "  \"explanation\": \"brief reason\"\n",
    "}}\n",
    "\"\"\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                out = json.loads(response['message']['content'])\n",
    "                return out.get(\"intent\", \"GENERAL\"), out.get(\"params\", {}), out.get(\"confidence\", 0.5), out.get(\"explanation\", \"\")\n",
    "            except Exception as e:\n",
    "                pass  # Silent fail, no print\n",
    "\n",
    "        # Fallback rule-based\n",
    "        text = text.lower()\n",
    "        if \"open youtube\" in text:\n",
    "            return \"OPEN_YOUTUBE\", {}, 0.95, \"Direct match\"\n",
    "        if \"play\" in text and \"youtube\" in text:\n",
    "            query = text.replace(\"play\", \"\").replace(\"on youtube\", \"\").strip()\n",
    "            return \"PLAY_YOUTUBE\", {\"query\": query}, 0.9, \"YouTube search\"\n",
    "        if \"play next\" in text or \"next video\" in text:\n",
    "            return \"PLAY_NEXT\", {}, 0.85, \"Continue video\"\n",
    "        if \"open\" in text:\n",
    "            apps = text.replace(\"open\", \"\").strip().replace(\" + \", \"+\").split(\"+\")\n",
    "            return \"OPEN_APP\", {\"app_names\": apps}, 0.8, \"Multiple app open\"\n",
    "        if any(p in text for p in [\"tell me about\", \"who is\", \"what is\", \"explain\"]):\n",
    "            topic = text.split(maxsplit=3)[-1] if len(text.split()) > 3 else text\n",
    "            return \"KNOWLEDGE\", {\"topic\": topic}, 0.9, \"Knowledge query\"\n",
    "        if \"research\" in text:\n",
    "            topic = text.replace(\"research\", \"\").strip()\n",
    "            return \"RESEARCH\", {\"topic\": topic}, 0.9, \"Research request\"\n",
    "        if \"battery\" in text:\n",
    "            return \"BATTERY_STATUS\", {}, 0.95, \"Battery query\"\n",
    "        if any(w in text for w in [\"ram\", \"cpu\", \"system\"]):\n",
    "            return \"SYSTEM_STATUS\", {}, 0.9, \"System status\"\n",
    "        if any(p in text for p in [\"memory status\", \"recent commands\", \"do you remember\"]):\n",
    "            return \"MEMORY_STATUS\", {}, 0.85, \"Memory recall\"\n",
    "        return \"GENERAL\", {}, 0.5, \"No clear intent\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# TOOLS\n",
    "# ==================================================\n",
    "class Tools:\n",
    "    APP_PATHS = {\n",
    "        \"chrome\": r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "        \"notepad\": \"notepad.exe\",\n",
    "        \"calculator\": \"calc.exe\",\n",
    "        \"camera\": \"start microsoft.windows.camera:\",\n",
    "        \"edge\": \"msedge\",\n",
    "        \"word\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\WINWORD.EXE\",\n",
    "        \"excel\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\EXCEL.EXE\",\n",
    "        \"powerpoint\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\POWERPNT.EXE\",\n",
    "        \"explorer\": \"explorer.exe\",\n",
    "        \"whatsapp\": \"https://web.whatsapp.com\",\n",
    "        \"youtube\": \"https://www.youtube.com\"\n",
    "    }\n",
    "\n",
    "    def open_app(self, app_names):\n",
    "        if not isinstance(app_names, list):\n",
    "            app_names = [app_names]\n",
    "        results = []\n",
    "        for name in app_names:\n",
    "            name = name.lower()\n",
    "            if name in [\"youtube\", \"whatsapp\"]:\n",
    "                webbrowser.open(self.APP_PATHS[name])\n",
    "                results.append(f\"{name.capitalize()} opened\")\n",
    "            elif name in self.APP_PATHS:\n",
    "                subprocess.Popen(self.APP_PATHS[name], shell=True)\n",
    "                results.append(f\"{name.capitalize()} opened\")\n",
    "            else:\n",
    "                results.append(f\"{name.capitalize()} not supported\")\n",
    "        return \"\\n\".join(results)\n",
    "\n",
    "    def open_youtube(self):\n",
    "        webbrowser.open(\"https://www.youtube.com\")\n",
    "        return \"YouTube opened\"\n",
    "\n",
    "    def play_youtube(self, query):\n",
    "        url = f\"https://www.youtube.com/results?search_query={urllib.parse.quote(query)}\"\n",
    "        webbrowser.open(url)\n",
    "        return f\"Searching YouTube for '{query}'\"\n",
    "\n",
    "    def play_next(self, last_topic):\n",
    "        if not last_topic:\n",
    "            return \"No previous topic.\"\n",
    "        return self.play_youtube(last_topic + \" next episode\")\n",
    "\n",
    "    def detailed_battery_status(self):\n",
    "        battery = psutil.sensors_battery()\n",
    "        if not battery:\n",
    "            return \"No battery detected.\"\n",
    "        percent = battery.percent\n",
    "        status = \"charging\" if battery.power_plugged else \"running on battery\"\n",
    "        secs_left = battery.secsleft\n",
    "        if secs_left == psutil.POWER_TIME_UNLIMITED:\n",
    "            time_left = \"Unlimited\"\n",
    "        elif secs_left == psutil.POWER_TIME_UNKNOWN:\n",
    "            time_left = \"Unknown\"\n",
    "        else:\n",
    "            hours = secs_left // 3600\n",
    "            mins = (secs_left % 3600) // 60\n",
    "            time_left = f\"{hours}h {mins}m remaining\"\n",
    "        return f\"Battery: {percent}% ({status}). {time_left}\"\n",
    "\n",
    "    def system_status(self):\n",
    "        cpu = psutil.cpu_percent(interval=0.1)\n",
    "        ram = psutil.virtual_memory()\n",
    "        return f\"CPU: {cpu}%. RAM: {ram.percent}% ({round(ram.used / (1024**3), 2)}/{round(ram.total / (1024**3), 2)} GB)\"\n",
    "\n",
    "    def knowledge(self, topic, voice):\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{topic.replace(' ', '_')}\"\n",
    "            res = requests.get(url, timeout=8).json()\n",
    "            extract = res.get(\"extract\", \"No information.\")\n",
    "            lines = extract.split(\". \")[:5]\n",
    "            summary = \". \".join(lines) + \".\"\n",
    "            voice.speak(summary)\n",
    "            voice.speak(\"Open full article?\")\n",
    "            reply = voice.listen_once()\n",
    "            if \"yes\" in reply or \"open\" in reply:\n",
    "                webbrowser.open(f\"https://en.wikipedia.org/wiki/{topic.replace(' ', '_')}\")\n",
    "                return summary + \" Full page opened.\"\n",
    "            return summary\n",
    "        except:\n",
    "            webbrowser.open(f\"https://www.google.com/search?q={topic}\")\n",
    "            return \"Searching web.\"\n",
    "\n",
    "    def research(self, topic, voice):\n",
    "        with open(NOTES_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\nResearch: '{topic}' at {datetime.now()}\\n\")\n",
    "        webbrowser.open(f\"https://www.google.com/search?q={topic}\")\n",
    "        return f\"Researching '{topic}'. Notes saved.\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# EXECUTOR\n",
    "# ==================================================\n",
    "class Executor:\n",
    "    def __init__(self):\n",
    "        self.tools = Tools()\n",
    "\n",
    "    def execute(self, intent, params, memory, voice):\n",
    "        try:\n",
    "            if intent == \"OPEN_APP\":\n",
    "                return self.tools.open_app(params.get(\"app_names\", []))\n",
    "            if intent == \"OPEN_YOUTUBE\":\n",
    "                return self.tools.open_youtube()\n",
    "            if intent == \"PLAY_YOUTUBE\":\n",
    "                query = params.get(\"query\", \"\")\n",
    "                memory.update_context(\"last_topic\", query)\n",
    "                return self.tools.play_youtube(query)\n",
    "            if intent == \"PLAY_NEXT\":\n",
    "                last = memory.get_context(\"last_topic\")\n",
    "                return self.tools.play_next(last)\n",
    "            if intent == \"KNOWLEDGE\":\n",
    "                return self.tools.knowledge(params.get(\"topic\", \"\"), voice)\n",
    "            if intent == \"BATTERY_STATUS\":\n",
    "                return self.tools.detailed_battery_status()\n",
    "            if intent == \"SYSTEM_STATUS\":\n",
    "                return self.tools.system_status()\n",
    "            if intent == \"RESEARCH\":\n",
    "                return self.tools.research(params.get(\"topic\", \"\"), voice)\n",
    "            if intent == \"MEMORY_STATUS\":\n",
    "                recent = memory.get_recent_commands(6)\n",
    "                last = memory.get_context(\"last_action\")\n",
    "                response = \"Recent commands:\\n\" + \"\\n\".join(f\"- {c}\" for c in recent)\n",
    "                if last:\n",
    "                    response += f\"\\nLast action: {last}\"\n",
    "                return response or \"No history.\"\n",
    "            return \"Command executed.\"\n",
    "        except Exception as e:\n",
    "            voice.speak(\"Action failed. Trying fallback.\")\n",
    "            return f\"Fallback result: {str(e)}\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# CRITIC AGENT\n",
    "# ==================================================\n",
    "class Critic:\n",
    "    def evaluate(self, step, result):\n",
    "        if ollama:\n",
    "            prompt = f\"Evaluate step '{step}' with result '{result}'. Success? JSON: {{'success': true/false, 'feedback': '...' }}\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                out = json.loads(response['message']['content'])\n",
    "                return out['success'], out['feedback']\n",
    "            except:\n",
    "                pass\n",
    "        return True, \"Assumed good.\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# DASHBOARD\n",
    "# ==================================================\n",
    "class Dashboard:\n",
    "    def __init__(self, friday):\n",
    "        self.friday = friday\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"FRIDAY - Agentic Assistant\")\n",
    "        self.root.geometry(\"900x650\")\n",
    "        self.root.configure(bg=\"#1e1e1e\")\n",
    "\n",
    "        tk.Label(self.root, text=\"FRIDAY\", font=(\"Arial\", 20, \"bold\"), fg=\"#00ffcc\", bg=\"#1e1e1e\").pack(pady=15)\n",
    "        self.status = tk.Label(self.root, text=\"Status: Booting...\", fg=\"yellow\", bg=\"#1e1e1e\", font=(\"Arial\", 12))\n",
    "        self.status.pack()\n",
    "\n",
    "        self.logs = scrolledtext.ScrolledText(self.root, height=22, bg=\"#2d2d2d\", fg=\"white\", font=(\"Consolas\", 10))\n",
    "        self.logs.pack(padx=15, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        btn_frame = tk.Frame(self.root, bg=\"#1e1e1e\")\n",
    "        btn_frame.pack(pady=10)\n",
    "        tk.Button(btn_frame, text=\"Upload Document\", command=self.upload, bg=\"#333\", fg=\"white\", width=15).grid(row=0, column=0, padx=15)\n",
    "        tk.Button(btn_frame, text=\"View Memory\", command=self.view_memory, bg=\"#333\", fg=\"white\", width=15).grid(row=0, column=1, padx=15)\n",
    "\n",
    "        # Chat interface\n",
    "        self.chat_frame = tk.Frame(self.root, bg=\"#1e1e1e\")\n",
    "        self.chat_logs = scrolledtext.ScrolledText(self.chat_frame, height=22, bg=\"#2d2d2d\", fg=\"white\", font=(\"Consolas\", 10))\n",
    "        self.chat_logs.pack(padx=15, pady=10, fill=tk.BOTH, expand=True)\n",
    "        self.input_frame = tk.Frame(self.chat_frame, bg=\"#1e1e1e\")\n",
    "        self.input_frame.pack(fill=tk.X)\n",
    "        self.input_entry = tk.Entry(self.input_frame, bg=\"#333\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.input_entry.pack(side=tk.LEFT, padx=15, pady=5, fill=tk.X, expand=True)\n",
    "        self.input_entry.bind(\"<Return>\", lambda event: self.friday.send_chat_message())\n",
    "        self.voice_button = tk.Button(self.input_frame, text=\"Voice\", command=self.friday.voice_chat_input, bg=\"#333\", fg=\"white\", width=10)\n",
    "        self.voice_button.pack(side=tk.LEFT, padx=5)\n",
    "        self.send_button = tk.Button(self.input_frame, text=\"Send\", command=self.friday.send_chat_message, bg=\"#333\", fg=\"white\", width=10)\n",
    "        self.send_button.pack(side=tk.LEFT, padx=5)\n",
    "        self.chat_frame.pack_forget()  # hide initially\n",
    "\n",
    "    def log(self, text):\n",
    "        self.logs.insert(tk.END, f\"{datetime.now().strftime('%H:%M:%S')} | {text}\\n\")\n",
    "        self.logs.see(tk.END)\n",
    "\n",
    "    def upload(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Documents\", \"*.pdf *.docx *.txt\")])\n",
    "        if path:\n",
    "            self.friday.process_document(path)\n",
    "\n",
    "    def view_memory(self):\n",
    "        try:\n",
    "            with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            messagebox.showinfo(\"Memory\", content[:4000] + (\"\\n...\" if len(content) > 4000 else \"\"))\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "    def update(self):\n",
    "        self.root.update_idletasks()\n",
    "        self.root.update()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# REASONING ENGINE (FULL MULTI-STAGE WITH DAG + NEW FEATURES)\n",
    "# ==================================================\n",
    "class ReasoningEngine:\n",
    "    def __init__(self, voice, memory, executor):\n",
    "        self.voice = voice\n",
    "        self.memory = memory\n",
    "        self.executor = executor\n",
    "\n",
    "    def think(self, command):\n",
    "        self.voice.speak(\"Reasoning through the problem\")\n",
    "        if ollama:\n",
    "            prompt = f\"Think step-by-step about this user command: '{command}'. Provide a clear reasoning trace.\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                reasoning = response['message']['content']\n",
    "            except:\n",
    "                reasoning = \"Analyzing user objective\"\n",
    "        else:\n",
    "            reasoning = \"Analyzing user objective\"\n",
    "        self.voice.speak(reasoning)\n",
    "        return reasoning\n",
    "\n",
    "    def plan(self, command):\n",
    "        self.voice.speak(\"Goal → task decomposition\")\n",
    "        if ollama:\n",
    "            prompt = f\"Decompose this goal into sub-tasks with dependencies as JSON DAG: '{{ \\\"tasks\\\": [{{\\\"id\\\": 1, \\\"description\\\": \\\"step1\\\", \\\"dependencies\\\": []}}, {{ \\\"id\\\": 2, \\\"description\\\": \\\"step2\\\", \\\"dependencies\\\": [1]}} ] }}' for '{command}'\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                dag = json.loads(response['message']['content'])\n",
    "            except:\n",
    "                dag = {\"tasks\": [{\"id\": 1, \"description\": command, \"dependencies\": []}]}\n",
    "        else:\n",
    "            dag = {\"tasks\": [{\"id\": 1, \"description\": command, \"dependencies\": []}]}\n",
    "        self.voice.speak(\"Sub-task dependency handling (DAG)\")\n",
    "        return dag\n",
    "\n",
    "    def execute_dag(self, dag, intent, params):\n",
    "        self.voice.speak(\"Self-driven execution\")\n",
    "        task_map = {t['id']: t for t in dag.get('tasks', [])}\n",
    "        completed = set()\n",
    "        results = {}\n",
    "        while len(completed) < len(task_map):\n",
    "            executed = False\n",
    "            for tid, task in task_map.items():\n",
    "                if tid in completed:\n",
    "                    continue\n",
    "                deps = task.get('dependencies', [])\n",
    "                if all(d in completed for d in deps):\n",
    "                    self.voice.speak(f\"Executing sub-task {tid}: {task['description']}\")\n",
    "                    result = self.executor.execute(intent, params, self.memory, self.voice)\n",
    "                    results[tid] = result\n",
    "                    completed.add(tid)\n",
    "                    executed = True\n",
    "                    break\n",
    "            if not executed:\n",
    "                self.voice.speak(\"Dependency cycle detected or no progress. Aborting.\")\n",
    "                break\n",
    "        return results, task_map  # ← Return task_map too\n",
    "\n",
    "    def reflect(self, command, result):\n",
    "        self.voice.speak(\"Listening\")\n",
    "        if ollama:\n",
    "            prompt = f\"Reflect on command '{command}' with result '{result}'. What went well? What could be improved?\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                reflection = response['message']['content']\n",
    "            except:\n",
    "                reflection = \"Action completed\"\n",
    "        else:\n",
    "            reflection = \"Action completed\"\n",
    "        self.voice.speak(reflection)\n",
    "        return reflection\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# FRIDAY CORE - FULL AGENTIC COGNITION\n",
    "# ==================================================\n",
    "class FRIDAY:\n",
    "    def __init__(self):\n",
    "        self.voice = VoiceEngine()\n",
    "        self.memory = MemoryEngine()\n",
    "        self.intent_engine = IntentEngine()\n",
    "        self.executor = Executor()\n",
    "        self.reasoning = ReasoningEngine(self.voice, self.memory, self.executor)\n",
    "        self.critic = Critic()\n",
    "        self.dashboard = Dashboard(self)\n",
    "        self.autonomous = False\n",
    "        self.command_mode = False\n",
    "\n",
    "    def authenticate(self):\n",
    "        self.voice.speak(\"Authentication required.\")\n",
    "        self.dashboard.log(\"Authentication started\")\n",
    "        self.dashboard.status.config(text=\"Status: Authenticating...\", fg=\"orange\")\n",
    "\n",
    "        while True:\n",
    "            mode = input(\"\\nPress 'v' for Voice or 't' for Text password: \").lower().strip()\n",
    "            if mode == 'v':\n",
    "                self.voice.speak(\"Say your password.\")\n",
    "                for _ in range(3):\n",
    "                    said = self.voice.listen_once()\n",
    "                    if said.strip() == PASSWORD.lower():\n",
    "                        self.voice.speak(\"Access granted. FRIDAY online.\")\n",
    "                        self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                        return True\n",
    "                    self.voice.speak(\"Incorrect.\")\n",
    "                return False\n",
    "            elif mode == 't':\n",
    "                typed = getpass.getpass(\"Enter password: \")\n",
    "                if typed == PASSWORD:\n",
    "                    self.voice.speak(\"Access granted. FRIDAY online.\")\n",
    "                    self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                    return True\n",
    "                print(\"Wrong.\")\n",
    "                for _ in range(2):\n",
    "                    typed = getpass.getpass(\"Try again: \")\n",
    "                    if typed == PASSWORD:\n",
    "                        self.voice.speak(\"Access granted.\")\n",
    "                        self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                        return True\n",
    "                    print(\"Wrong.\")\n",
    "                return False\n",
    "\n",
    "    def process_document(self, path):\n",
    "        self.dashboard.log(f\"Uploaded: {os.path.basename(path)}\")\n",
    "        self.voice.speak(\"Document received.\")\n",
    "\n",
    "    def activate_command_mode(self):\n",
    "        if ollama is None:\n",
    "            self.voice.speak(\"Ollama is not available.\")\n",
    "            return\n",
    "        self.command_mode = True\n",
    "        self.voice.speak(\"Command mode activated.\")\n",
    "        self.dashboard.log(\"Command mode activated.\")\n",
    "        self.dashboard.logs.pack_forget()\n",
    "        self.dashboard.chat_frame.pack(pady=10, fill=tk.BOTH, expand=True)\n",
    "        self.dashboard.chat_logs.delete(1.0, tk.END)\n",
    "        for msg in self.memory.data[\"chatbot_history\"]:\n",
    "            role = \"You\" if msg[\"role\"] == \"user\" else \"FRIDAY\"\n",
    "            self.dashboard.chat_logs.insert(tk.END, f\"{role}: {msg['content']}\\n\\n\")\n",
    "        self.dashboard.chat_logs.see(tk.END)\n",
    "\n",
    "    def deactivate_command_mode(self):\n",
    "        self.command_mode = False\n",
    "        self.voice.speak(\"Command mode deactivated.\")\n",
    "        self.dashboard.log(\"Command mode deactivated.\")\n",
    "        self.dashboard.chat_frame.pack_forget()\n",
    "        self.dashboard.logs.pack()\n",
    "\n",
    "    def send_chat_message(self):\n",
    "        message = self.dashboard.input_entry.get().strip().lower()\n",
    "        self.dashboard.input_entry.delete(0, tk.END)\n",
    "        if message:\n",
    "            self.process_chat_message(message)\n",
    "\n",
    "    def voice_chat_input(self):\n",
    "        message = self.voice.listen_once()\n",
    "        if message:\n",
    "            self.process_chat_message(message)\n",
    "\n",
    "    def process_chat_message(self, message):\n",
    "        if message == \"exit command mode\":\n",
    "            self.deactivate_command_mode()\n",
    "            return\n",
    "        self.dashboard.chat_logs.insert(tk.END, f\"You: {message}\\n\\n\")\n",
    "        self.dashboard.chat_logs.see(tk.END)\n",
    "        self.dashboard.root.update()\n",
    "        self.memory.data[\"chatbot_history\"].append({\"role\": \"user\", \"content\": message})\n",
    "        try:\n",
    "            response = ollama.chat(model='llama3', messages=self.memory.data[\"chatbot_history\"])\n",
    "            assistant_reply = response['message']['content']\n",
    "            self.memory.data[\"chatbot_history\"].append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "            self.memory.save()\n",
    "            self.voice.speak(assistant_reply)\n",
    "            self.dashboard.chat_logs.insert(tk.END, f\"FRIDAY: {assistant_reply}\\n\\n\")\n",
    "            self.dashboard.chat_logs.see(tk.END)\n",
    "            self.memory.store_conversation(message, assistant_reply)\n",
    "        except Exception as e:\n",
    "            self.voice.speak(\"Error in command mode.\")\n",
    "            self.dashboard.chat_logs.insert(tk.END, f\"Error: {str(e)}\\n\\n\")\n",
    "\n",
    "    def run(self):\n",
    "        if not self.authenticate():\n",
    "            return\n",
    "\n",
    "        self.dashboard.log(\"FRIDAY activated with multi-stage cognition\")\n",
    "        self.voice.speak(\"Autonomous multi-stage agentic cognition online.\")\n",
    "\n",
    "        while True:\n",
    "            self.dashboard.update()\n",
    "\n",
    "            if self.command_mode:\n",
    "                continue  # Removed sleep for speed\n",
    "\n",
    "            mode = input(\"\\nPress 'v' for Voice, 't' for Text, 'q' to quit: \").lower().strip()\n",
    "            if mode == 'q':\n",
    "                self.voice.speak(\"Shutting down. Goodbye.\")\n",
    "                break\n",
    "            elif mode == 'v':\n",
    "                command = self.voice.continuous_listen()\n",
    "            elif mode == 't':\n",
    "                command = input(\"You (text): \").strip()\n",
    "            else:\n",
    "                print(\"Use v, t, or q.\")\n",
    "                continue\n",
    "\n",
    "            if not command:\n",
    "                continue\n",
    "\n",
    "            if command == \"command mode activate\":\n",
    "                self.activate_command_mode()\n",
    "                continue\n",
    "            elif command == \"exit command mode\":\n",
    "                if self.command_mode:\n",
    "                    self.deactivate_command_mode()\n",
    "                continue\n",
    "\n",
    "            self.dashboard.log(f\"You: {command}\")\n",
    "\n",
    "            history = self.memory.data[\"short\"]\n",
    "            context = self.memory.data[\"context\"]\n",
    "\n",
    "            # Intent + Confidence + Explanation\n",
    "            intent, params, confidence, explanation = self.intent_engine.analyze(command, history, context)\n",
    "            self.dashboard.log(f\"Intent identified as: {intent}\")\n",
    "            self.voice.speak(f\"Intent identified as {intent}\")\n",
    "\n",
    "            if confidence < 0.7:\n",
    "                self.voice.speak(\"Low confidence. Clarifying.\")\n",
    "                clarification = self.voice.listen_once() or input(\"Clarify: \")\n",
    "                command += \" \" + clarification\n",
    "                intent, params, confidence, explanation = self.intent_engine.analyze(command, history, context)\n",
    "\n",
    "            # Multi-Stage Reasoning\n",
    "            self.dashboard.log(\"REASONING: Analyzing user objective\")\n",
    "            self.voice.speak(\"Analyzing user objective\")\n",
    "            think = self.reasoning.think(command)\n",
    "            self.dashboard.log(f\"REASONING: {think}\")\n",
    "\n",
    "            self.dashboard.log(\"REASONING: Selecting best available knowledge source\")\n",
    "            self.voice.speak(\"Selecting best available knowledge source\")\n",
    "            dag = self.reasoning.plan(command)\n",
    "            self.dashboard.log(f\"REASONING: Preparing fallback strategy if needed\")\n",
    "            self.voice.speak(\"Preparing fallback strategy if needed\")\n",
    "\n",
    "            # Action → Outcome → Evaluation loop with failure detection\n",
    "            self.dashboard.log(\"Action → Outcome → Evaluation loop\")\n",
    "            self.voice.speak(\"Action → Outcome → Evaluation loop\")\n",
    "            results, task_map = self.reasoning.execute_dag(dag, intent, params)  # ← Now receives task_map\n",
    "\n",
    "            for tid, result in results.items():\n",
    "                step_description = task_map.get(tid, {}).get('description', 'Unknown step')\n",
    "                success, feedback = self.critic.evaluate(step_description, result)\n",
    "                self.dashboard.log(f\"Evaluation: {'Success' if success else 'Failed'} - {feedback}\")\n",
    "\n",
    "                if not success:\n",
    "                    self.voice.speak(\"Failure detection + alternative strategy\")\n",
    "                    alt_prompt = f\"Alternative strategy for failed task {tid}: {feedback}\"\n",
    "                    alt_dag = self.reasoning.plan(alt_prompt)\n",
    "                    alt_results, _ = self.reasoning.execute_dag(alt_dag, intent, params)\n",
    "                    results[tid] = list(alt_results.values())[0] if alt_results else \"Alternative failed\"\n",
    "\n",
    "            final_result = json.dumps(results, indent=2)\n",
    "            self.dashboard.log(f\"FRIDAY: {final_result}\")\n",
    "            self.voice.speak(final_result)\n",
    "\n",
    "            self.memory.update_context(\"last_action\", command)\n",
    "            self.memory.store_conversation(command, final_result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FRIDAY().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
