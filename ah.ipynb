{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.99)\n",
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: comtypes in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.13)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Downloading speechrecognition-3.14.4-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/32.9 MB 4.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.6/32.9 MB 3.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/32.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.4/32.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 4.7/32.9 MB 4.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.5/32.9 MB 4.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.6/32.9 MB 4.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 7.9/32.9 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 9.2/32.9 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 10.7/32.9 MB 5.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 12.3/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 13.4/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 14.7/32.9 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 15.7/32.9 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 16.5/32.9 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 17.0/32.9 MB 5.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 17.6/32.9 MB 5.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 18.6/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 19.7/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 21.0/32.9 MB 5.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 21.8/32.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 23.1/32.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 24.4/32.9 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 26.0/32.9 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 27.3/32.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 28.0/32.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 28.8/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 29.6/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 30.9/32.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 31.7/32.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.5/32.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 4.9 MB/s  0:00:06\n",
      "Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio, SpeechRecognition\n",
      "\n",
      "   -------------------- ------------------- 1/2 [SpeechRecognition]\n",
      "   -------------------- ------------------- 1/2 [SpeechRecognition]\n",
      "   ---------------------------------------- 2/2 [SpeechRecognition]\n",
      "\n",
      "Successfully installed SpeechRecognition-3.14.4 pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil requests pyttsx3 SpeechRecognition pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipwin\n",
      "  Downloading pipwin-0.5.2.tar.gz (7.9 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting docopt (from pipwin)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (2.32.3)\n",
      "Collecting pyprind (from pipwin)\n",
      "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (4.12.3)\n",
      "Collecting js2py (from pipwin)\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Requirement already satisfied: packaging in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pipwin) (24.1)\n",
      "Collecting pySmartDL>=1.3.1 (from pipwin)\n",
      "  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.9.0->pipwin) (2.5)\n",
      "Collecting tzlocal>=1.2 (from js2py->pipwin)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pyjsparser>=2.5.1 (from js2py->pipwin)\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tzdata in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from tzlocal>=1.2->js2py->pipwin) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests->pipwin) (2024.8.30)\n",
      "Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
      "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.1 MB/s  0:00:00\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Building wheels for collected packages: pipwin, docopt, pyjsparser\n",
      "  Building wheel for pipwin (pyproject.toml): started\n",
      "  Building wheel for pipwin (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pipwin: filename=pipwin-0.5.2-py2.py3-none-any.whl size=8874 sha256=f6317c38f05d7ee5ad91ee50b2745ab33d0bae62b5cffd6c3d6a1267e4812ade\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\e8\\b5\\1d\\b94f69a230c016fe50ed36399dec48b34b82a11e4f344e9ccb\n",
      "  Building wheel for docopt (pyproject.toml): started\n",
      "  Building wheel for docopt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13858 sha256=f7c68d1b1eb50e3a0f62088a1061c4cabf088f48927ca6bbc5aaef5302d20522\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for pyjsparser (pyproject.toml): started\n",
      "  Building wheel for pyjsparser (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=26014 sha256=aef97d513ad63c0900ac569becf96203126800e45a2cf0c2623a47da078d4a55\n",
      "  Stored in directory: c:\\users\\p r vishal\\appdata\\local\\pip\\cache\\wheels\\14\\32\\1d\\9ef7b582e358446aeef4b9052aa89ef4dffa1688c1aae8aa13\n",
      "Successfully built pipwin docopt pyjsparser\n",
      "Installing collected packages: pySmartDL, pyprind, pyjsparser, docopt, tzlocal, js2py, pipwin\n",
      "\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------- ----------- 5/7 [js2py]\n",
      "   ---------------------------------------- 7/7 [pipwin]\n",
      "\n",
      "Successfully installed docopt-0.6.2 js2py-0.74 pipwin-0.5.2 pySmartDL-1.3.4 pyjsparser-2.7.1 pyprind-2.11.3 tzlocal-5.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\P R VISHAL\\anaconda3\\Scripts\\pipwin.exe\\__main__.py\", line 2, in <module>\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\pipwin\\command.py\", line 28, in <module>\n",
      "    from . import pipwin, __version__\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\pipwin\\pipwin.py\", line 13, in <module>\n",
      "    import js2py\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\__init__.py\", line 72, in <module>\n",
      "    from .base import PyJsException\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 2965, in <module>\n",
      "    @Js\n",
      "     ^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 165, in Js\n",
      "    return PyJsFunction(val, FunctionPrototype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\base.py\", line 1377, in __init__\n",
      "    cand = fix_js_args(func)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\utils\\injector.py\", line 27, in fix_js_args\n",
      "    code = append_arguments(six.get_function_code(func), ('this', 'arguments'))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\P R VISHAL\\anaconda3\\Lib\\site-packages\\js2py\\utils\\injector.py\", line 121, in append_arguments\n",
      "    arg = name_translations[inst.arg]\n",
      "          ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 3\n"
     ]
    }
   ],
   "source": [
    "!pip install pipwin\n",
    "!pipwin install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic>=2.9->ollama)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 621.2 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 780.2 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 762.0 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 762.0 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.3/2.0 MB 729.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 729.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 704.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 662.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 681.9 kB/s  0:00:02\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, typing-inspection, pydantic-core, pydantic, ollama\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "  Attempting uninstall: pydantic-core\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "  Attempting uninstall: pydantic\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "   ---------------- ----------------------- 2/5 [pydantic-core]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   ------------------------ --------------- 3/5 [pydantic]\n",
      "   -------------------------------- ------- 4/5 [ollama]\n",
      "   ---------------------------------------- 5/5 [ollama]\n",
      "\n",
      "Successfully installed ollama-0.6.1 pydantic-2.12.5 pydantic-core-2.41.5 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama psutil requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\p r vishal\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama psutil requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIDAY: Authentication required.\n",
      "FRIDAY: Access granted. FRIDAY online.\n",
      "FRIDAY: Autonomous multi-stage agentic cognition online.\n",
      "FRIDAY: Command mode activated.\n",
      "FRIDAY: Hi! How's it going?\n",
      "FRIDAY: Preparing for an interview can be a daunting task, but with some guidance and practice, you'll be well-prepared to ace the conversation. Here are some tips to get you started:\n",
      "\n",
      "**Before the Interview**\n",
      "\n",
      "1. **Research the company**: Learn as much as you can about the company culture, values, products/services, and current projects.\n",
      "2. **Review your resume**: Make sure it's up-to-date and highlights your relevant skills and experiences.\n",
      "3. **Prepare common interview questions**: Look at job descriptions, industry reports, or online resources to get an idea of common interview questions for the role you're applying for.\n",
      "\n",
      "**During the Interview**\n",
      "\n",
      "1. **Arrive early**: Plan to arrive 10-15 minutes before the scheduled time to show your enthusiasm and punctuality.\n",
      "2. **Dress professionally**: Wear attire that's appropriate for the industry and job type.\n",
      "3. **Be ready to talk about your skills and experiences**: Be prepared to give specific examples of how you've applied your skills in previous roles.\n",
      "4. **Ask insightful questions**: Prepare a list of thoughtful questions to ask the interviewer, such as \"What are the biggest challenges facing the team right now?\" or \"Can you tell me more about the company culture?\"\n",
      "5. **Maintain good posture and eye contact**: Sit up straight, make eye contact, and use confident body language.\n",
      "\n",
      "**After the Interview**\n",
      "\n",
      "1. **Send a thank-you note**: Write a brief email or letter to express your gratitude for the opportunity to interview.\n",
      "2. **Follow up on any next steps**: If the interviewer mentions specific tasks or deadlines, be sure to follow up with them promptly.\n",
      "\n",
      "Some additional tips to help you prepare:\n",
      "\n",
      "* Practice answering behavioral questions using the STAR method ( Situation, Task, Action, Result).\n",
      "* Prepare a list of 3-5 key accomplishments you're proud of and can talk about confidently.\n",
      "* Think about how your skills and experiences align with the company's goals and values.\n",
      "* Be ready to explain why you want to work for this company and what you can bring to the role.\n",
      "\n",
      "Do you have any specific areas you'd like me to focus on (e.g., common interview questions, salary negotiation)?\n",
      "FRIDAY: It seems like you're opening multiple applications!\n",
      "\n",
      "* **Notepad**: A simple text editor for Windows.\n",
      "* **Chrome**: A popular web browser developed by Google.\n",
      "* **WhatsApp**: A messaging app for smartphones.\n",
      "\n",
      "Are you planning to take notes, browse the internet, or chat with someone on WhatsApp?\n",
      "FRIDAY: It seems like you're referring to a text editor!\n",
      "\n",
      "* **Command mode** is usually activated when you press the \"Escape\" key (or use a hotkey) in a text editor. This allows you to enter commands, such as deleting lines or moving around the document.\n",
      "* **Deactivating command mode**: To exit command mode, you can press the \"Insert\" key or use another hotkey specific to your text editor.\n",
      "\n",
      "By deactivating command mode, you'll return to normal typing mode, and you can start editing your text without having to enter commands.\n",
      "FRIDAY: Command mode deactivated.\n",
      "LLM intent error: Expecting value: line 1 column 1 (char 0)\n",
      "FRIDAY: Intent identified as OPEN_APP\n",
      "FRIDAY: Analyzing user objective\n",
      "FRIDAY: Reasoning through the problem\n",
      "FRIDAY: Here's the step-by-step reasoning for interpreting the user command \"open notepad+chrome\":\n",
      "\n",
      "1. **Tokenize**: Break down the command into individual words or tokens:\n",
      "\n",
      "\"open\", \"notepad\", \"+\", \"chrome\"\n",
      "\n",
      "2. **Identify the command verb**: Determine the primary action requested by the user:\n",
      "\n",
      "* The verb is \"open\". This suggests that the user wants to initiate a new process or application.\n",
      "\n",
      "3. **Analyze the arguments**: Examine the words following the verb:\n",
      "\n",
      "* \"notepad\" likely refers to a text editor or word processing software (Notepad).\n",
      "* \"+\" is an operator, which can indicate various possibilities:\n",
      "\t+ In some contexts, \"+\" might mean addition or concatenation.\n",
      "\t+ However, in this specific case, it's reasonable to assume that \"+chrome\" forms a compound command.\n",
      "* \"chrome\" probably refers to the Google Chrome web browser.\n",
      "\n",
      "4. **Interpret the compound command**: Given the presence of \"+\", it seems likely that the user wants to combine Notepad and Chrome into a single action:\n",
      "\n",
      "* Perhaps the user wants to open both applications simultaneously, or\n",
      "* Maybe they want to create a new document in Notepad and then open it in Chrome.\n",
      "\n",
      "5. **Determine the expected outcome**: Based on the command's meaning:\n",
      "\n",
      "* If the user intends to open both apps simultaneously, the expected outcome is that both Notepad and Chrome are launched.\n",
      "* If the user wants to create a new document in Notepad and open it in Chrome, the expected outcome is that a new Notepad file is created and then opened in Chrome.\n",
      "\n",
      "In either case, the goal is to initiate a process that involves both applications.\n",
      "FRIDAY: Selecting best available knowledge source\n",
      "FRIDAY: Goal → task decomposition\n",
      "FRIDAY: Sub-task dependency handling (DAG)\n",
      "FRIDAY: Preparing fallback strategy if needed\n",
      "FRIDAY: Action → Outcome → Evaluation loop\n",
      "FRIDAY: Self-driven execution\n",
      "FRIDAY: Executing sub-task 1: open notepad+chrome\n",
      "FRIDAY: {\n",
      "  \"1\": \"Notepad opened\\nChrome opened\"\n",
      "}\n",
      "FRIDAY: Shutting down. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import threading\n",
    "import webbrowser\n",
    "import time\n",
    "import urllib.parse\n",
    "import psutil\n",
    "import requests\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext, messagebox\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import pyttsx3\n",
    "except ImportError:\n",
    "    pyttsx3 = None\n",
    "\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except ImportError:\n",
    "    sr = None\n",
    "\n",
    "try:\n",
    "    import pvporcupine\n",
    "    from pvrecorder import PvRecorder\n",
    "except ImportError:\n",
    "    pvporcupine = None\n",
    "    PvRecorder = None\n",
    "\n",
    "try:\n",
    "    import ollama\n",
    "except ImportError:\n",
    "    ollama = None\n",
    "\n",
    "try:\n",
    "    import PyPDF2\n",
    "except ImportError:\n",
    "    PyPDF2 = None\n",
    "\n",
    "try:\n",
    "    from docx import Document\n",
    "except ImportError:\n",
    "    Document = None\n",
    "\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    BeautifulSoup = None\n",
    "\n",
    "try:\n",
    "    from duckduckgo_search import DDGS\n",
    "except ImportError:\n",
    "    DDGS = None\n",
    "\n",
    "# ==================================================\n",
    "# CONFIGURATION\n",
    "# ==================================================\n",
    "BASE_FOLDER = r\"C:\\Users\\P R VISHAL\\OneDrive\\Desktop\\FRIDAY..!!\"\n",
    "\n",
    "if not os.path.exists(BASE_FOLDER):\n",
    "    os.makedirs(BASE_FOLDER)\n",
    "    print(f\"[INFO] Created folder: {BASE_FOLDER}\")\n",
    "\n",
    "MEMORY_FILE = os.path.join(BASE_FOLDER, \"friday_memory.json\")\n",
    "NOTES_FILE = os.path.join(BASE_FOLDER, \"friday_notes.txt\")\n",
    "LAST_COMMANDS_FILE = os.path.join(BASE_FOLDER, \"friday_last_commands.txt\")\n",
    "\n",
    "PASSWORD = \"1234\"\n",
    "ACCESS_KEY = \"\"\n",
    "WAKE_WORD_PATH = \"\"\n",
    "\n",
    "# ==================================================\n",
    "# VOICE ENGINE\n",
    "# ==================================================\n",
    "class VoiceEngine:\n",
    "    def __init__(self):\n",
    "        self.enabled = pyttsx3 is not None\n",
    "        self.lock = threading.Lock()\n",
    "        if self.enabled:\n",
    "            self.engine = pyttsx3.init(driverName=\"sapi5\")\n",
    "            self.engine.setProperty(\"rate\", 165)\n",
    "            self.engine.setProperty(\"volume\", 1.0)\n",
    "            self.engine.say(\" \")\n",
    "            self.engine.runAndWait()\n",
    "\n",
    "    def speak(self, text):\n",
    "        print(\"FRIDAY:\", text)\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        with self.lock:\n",
    "            try:\n",
    "                self.engine.stop()\n",
    "                self.engine.say(text)\n",
    "                self.engine.runAndWait()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def listen_once(self):\n",
    "        if sr is None:\n",
    "            print(\"Speech recognition not available.\")\n",
    "            return \"\"\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            self.speak(\"Listening...\")\n",
    "            try:\n",
    "                audio = r.listen(source, timeout=5, phrase_time_limit=10)\n",
    "            except sr.WaitTimeoutError:\n",
    "                return \"\"\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"You (voice):\", text)\n",
    "            return text.lower()\n",
    "        except:\n",
    "            self.speak(\"I could not understand.\")\n",
    "            return \"\"\n",
    "\n",
    "    def continuous_listen(self):\n",
    "        if pvporcupine and ACCESS_KEY and WAKE_WORD_PATH:\n",
    "            try:\n",
    "                porcupine = pvporcupine.create(access_key=ACCESS_KEY, keyword_paths=[WAKE_WORD_PATH])\n",
    "                recorder = PvRecorder(frame_length=porcupine.frame_length)\n",
    "                recorder.start()\n",
    "                self.speak(\"Continuous listening activated. Say 'Hey Friday'\")\n",
    "                while True:\n",
    "                    pcm = recorder.read()\n",
    "                    if porcupine.process(pcm) >= 0:\n",
    "                        self.speak(\"Yes sir?\")\n",
    "                        cmd = self.listen_once()\n",
    "                        recorder.stop()\n",
    "                        porcupine.delete()\n",
    "                        recorder.delete()\n",
    "                        return cmd or \"\"\n",
    "            except Exception as e:\n",
    "                print(\"Wake word error:\", e)\n",
    "\n",
    "        self.speak(\"Wake word not configured. Using manual trigger.\")\n",
    "        return self.listen_once()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# MEMORY ENGINE - SAFE & AUTO-CREATE\n",
    "# ==================================================\n",
    "class MemoryEngine:\n",
    "    def __init__(self):\n",
    "        self.default_structure = {\n",
    "            \"short\": [],\n",
    "            \"long\": [],\n",
    "            \"context\": {\n",
    "                \"last_action\": \"\",\n",
    "                \"last_topic\": \"\",\n",
    "                \"last_search\": \"\"\n",
    "            },\n",
    "            \"chatbot_history\": []\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(MEMORY_FILE):\n",
    "            self.data = self.default_structure.copy()\n",
    "            self.save()\n",
    "            print(f\"[INFO] Created new memory file: {MEMORY_FILE}\")\n",
    "        else:\n",
    "            try:\n",
    "                self.load()\n",
    "                self.validate_and_fix()\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Memory file issue: {e}. Creating fresh one.\")\n",
    "                self.data = self.default_structure.copy()\n",
    "                self.save()\n",
    "\n",
    "        if not os.path.exists(NOTES_FILE):\n",
    "            with open(NOTES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"# FRIDAY Research Notes\\n\\n\")\n",
    "        if not os.path.exists(LAST_COMMANDS_FILE):\n",
    "            with open(LAST_COMMANDS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"# Recent Commands Log\\n\\n\")\n",
    "\n",
    "    def load(self):\n",
    "        with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def save(self):\n",
    "        with open(MEMORY_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.data, f, indent=2)\n",
    "\n",
    "    def validate_and_fix(self):\n",
    "        for key in self.default_structure:\n",
    "            if key not in self.data:\n",
    "                self.data[key] = self.default_structure[key]\n",
    "        if \"context\" not in self.data or not isinstance(self.data[\"context\"], dict):\n",
    "            self.data[\"context\"] = self.default_structure[\"context\"]\n",
    "        if not isinstance(self.data[\"short\"], list):\n",
    "            self.data[\"short\"] = []\n",
    "        if not isinstance(self.data[\"long\"], list):\n",
    "            self.data[\"long\"] = []\n",
    "        if \"chatbot_history\" not in self.data or not isinstance(self.data[\"chatbot_history\"], list):\n",
    "            self.data[\"chatbot_history\"] = []\n",
    "        self.save()\n",
    "\n",
    "    def update_context(self, key, value):\n",
    "        self.data[\"context\"][key] = value\n",
    "        self.save()\n",
    "\n",
    "    def get_context(self, key):\n",
    "        return self.data[\"context\"].get(key, \"\")\n",
    "\n",
    "    def get_recent_commands(self, n=6):\n",
    "        commands = []\n",
    "        for i in range(len(self.data[\"short\"]) - 1, -1, -2):\n",
    "            if i < len(self.data[\"short\"]) and self.data[\"short\"][i][\"role\"] == \"user\":\n",
    "                commands.append(self.data[\"short\"][i][\"content\"])\n",
    "            if len(commands) >= n:\n",
    "                break\n",
    "        return commands[::-1]\n",
    "\n",
    "    def store_conversation(self, user, assistant):\n",
    "        self.data[\"short\"].append({\"role\": \"user\", \"content\": user})\n",
    "        self.data[\"short\"].append({\"role\": \"assistant\", \"content\": assistant})\n",
    "        if len(self.data[\"short\"]) > 30:\n",
    "            self.data[\"long\"].extend(self.data[\"short\"][:10])\n",
    "            self.data[\"short\"] = self.data[\"short\"][10:]\n",
    "        self.save()\n",
    "\n",
    "        with open(LAST_COMMANDS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | You: {user}\\n\")\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | FRIDAY: {assistant}\\n\\n\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# INTENT ENGINE (LLM + CONFIDENCE + EXPLANATION)\n",
    "# ==================================================\n",
    "class IntentEngine:\n",
    "    def analyze(self, text, history, context):\n",
    "        fused_context = f\"Recent history: {json.dumps(history[-5:])}\\nContext: {json.dumps(context)}\\nSystem: CPU {psutil.cpu_percent()}%, RAM {psutil.virtual_memory().percent}%\"\n",
    "        if ollama:\n",
    "            prompt = f\"\"\"\n",
    "Analyze the user's intent for this command: \"{text}\"\n",
    "Context: {fused_context}\n",
    "Output only JSON:\n",
    "{{\n",
    "  \"intent\": \"OPEN_APP\" or \"PLAY_YOUTUBE\" or \"BATTERY_STATUS\" etc.,\n",
    "  \"params\": {{...}},\n",
    "  \"confidence\": 0.0 to 1.0,\n",
    "  \"explanation\": \"brief reason\"\n",
    "}}\n",
    "\"\"\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                out = json.loads(response['message']['content'])\n",
    "                return out.get(\"intent\", \"GENERAL\"), out.get(\"params\", {}), out.get(\"confidence\", 0.5), out.get(\"explanation\", \"\")\n",
    "            except Exception as e:\n",
    "                print(f\"LLM intent error: {e}\")\n",
    "\n",
    "        # Fallback rule-based\n",
    "        text = text.lower()\n",
    "        if \"open youtube\" in text:\n",
    "            return \"OPEN_YOUTUBE\", {}, 0.95, \"Direct match\"\n",
    "        if \"play\" in text and \"youtube\" in text:\n",
    "            query = text.replace(\"play\", \"\").replace(\"on youtube\", \"\").strip()\n",
    "            return \"PLAY_YOUTUBE\", {\"query\": query}, 0.9, \"YouTube search\"\n",
    "        if \"play next\" in text or \"next video\" in text:\n",
    "            return \"PLAY_NEXT\", {}, 0.85, \"Continue video\"\n",
    "        if \"open\" in text:\n",
    "            apps = text.replace(\"open\", \"\").strip().replace(\" + \", \"+\").split(\"+\")\n",
    "            return \"OPEN_APP\", {\"app_names\": apps}, 0.8, \"Multiple app open\"\n",
    "        if any(p in text for p in [\"tell me about\", \"who is\", \"what is\", \"explain\"]):\n",
    "            topic = text.split(maxsplit=3)[-1] if len(text.split()) > 3 else text\n",
    "            return \"KNOWLEDGE\", {\"topic\": topic}, 0.9, \"Knowledge query\"\n",
    "        if \"research\" in text:\n",
    "            topic = text.replace(\"research\", \"\").strip()\n",
    "            return \"RESEARCH\", {\"topic\": topic}, 0.9, \"Research request\"\n",
    "        if \"battery\" in text:\n",
    "            return \"BATTERY_STATUS\", {}, 0.95, \"Battery query\"\n",
    "        if any(w in text for w in [\"ram\", \"cpu\", \"system\"]):\n",
    "            return \"SYSTEM_STATUS\", {}, 0.9, \"System status\"\n",
    "        if any(p in text for p in [\"memory status\", \"recent commands\", \"do you remember\"]):\n",
    "            return \"MEMORY_STATUS\", {}, 0.85, \"Memory recall\"\n",
    "        return \"GENERAL\", {}, 0.5, \"No clear intent\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# TOOLS\n",
    "# ==================================================\n",
    "class Tools:\n",
    "    APP_PATHS = {\n",
    "        \"chrome\": r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "        \"notepad\": \"notepad.exe\",\n",
    "        \"calculator\": \"calc.exe\",\n",
    "        \"camera\": \"start microsoft.windows.camera:\",\n",
    "        \"edge\": \"msedge\",\n",
    "        \"word\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\WINWORD.EXE\",\n",
    "        \"excel\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\EXCEL.EXE\",\n",
    "        \"powerpoint\": r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\POWERPNT.EXE\",\n",
    "        \"explorer\": \"explorer.exe\",\n",
    "        \"whatsapp\": \"https://web.whatsapp.com\",\n",
    "        \"youtube\": \"https://www.youtube.com\"\n",
    "    }\n",
    "\n",
    "    def open_app(self, app_names):\n",
    "        if not isinstance(app_names, list):\n",
    "            app_names = [app_names]\n",
    "        results = []\n",
    "        for name in app_names:\n",
    "            name = name.lower()\n",
    "            if name in [\"youtube\", \"whatsapp\"]:\n",
    "                webbrowser.open(self.APP_PATHS[name])\n",
    "                results.append(f\"{name.capitalize()} opened\")\n",
    "            elif name in self.APP_PATHS:\n",
    "                subprocess.Popen(self.APP_PATHS[name], shell=True)\n",
    "                results.append(f\"{name.capitalize()} opened\")\n",
    "            else:\n",
    "                results.append(f\"{name.capitalize()} not supported\")\n",
    "        return \"\\n\".join(results)\n",
    "\n",
    "    def open_youtube(self):\n",
    "        webbrowser.open(\"https://www.youtube.com\")\n",
    "        return \"YouTube opened\"\n",
    "\n",
    "    def play_youtube(self, query):\n",
    "        url = f\"https://www.youtube.com/results?search_query={urllib.parse.quote(query)}\"\n",
    "        webbrowser.open(url)\n",
    "        return f\"Searching YouTube for '{query}'\"\n",
    "\n",
    "    def play_next(self, last_topic):\n",
    "        if not last_topic:\n",
    "            return \"No previous topic.\"\n",
    "        return self.play_youtube(last_topic + \" next episode\")\n",
    "\n",
    "    def detailed_battery_status(self):\n",
    "        battery = psutil.sensors_battery()\n",
    "        if not battery:\n",
    "            return \"No battery detected.\"\n",
    "        percent = battery.percent\n",
    "        status = \"charging\" if battery.power_plugged else \"running on battery\"\n",
    "        secs_left = battery.secsleft\n",
    "        if secs_left == psutil.POWER_TIME_UNLIMITED:\n",
    "            time_left = \"Unlimited\"\n",
    "        elif secs_left == psutil.POWER_TIME_UNKNOWN:\n",
    "            time_left = \"Unknown\"\n",
    "        else:\n",
    "            hours = secs_left // 3600\n",
    "            mins = (secs_left % 3600) // 60\n",
    "            time_left = f\"{hours}h {mins}m remaining\"\n",
    "        return f\"Battery: {percent}% ({status}). {time_left}\"\n",
    "\n",
    "    def system_status(self):\n",
    "        cpu = psutil.cpu_percent(interval=1)\n",
    "        ram = psutil.virtual_memory()\n",
    "        return f\"CPU: {cpu}%. RAM: {ram.percent}% ({round(ram.used / (1024**3), 2)}/{round(ram.total / (1024**3), 2)} GB)\"\n",
    "\n",
    "    def knowledge(self, topic, voice):\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{topic.replace(' ', '_')}\"\n",
    "            res = requests.get(url, timeout=8).json()\n",
    "            extract = res.get(\"extract\", \"No information.\")\n",
    "            lines = extract.split(\". \")[:5]\n",
    "            summary = \". \".join(lines) + \".\"\n",
    "            voice.speak(summary)\n",
    "            voice.speak(\"Open full article?\")\n",
    "            reply = voice.listen_once()\n",
    "            if \"yes\" in reply or \"open\" in reply:\n",
    "                webbrowser.open(f\"https://en.wikipedia.org/wiki/{topic.replace(' ', '_')}\")\n",
    "                return summary + \" Full page opened.\"\n",
    "            return summary\n",
    "        except:\n",
    "            webbrowser.open(f\"https://www.google.com/search?q={topic}\")\n",
    "            return \"Searching web.\"\n",
    "\n",
    "    def research(self, topic, voice):\n",
    "        with open(NOTES_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\nResearch: '{topic}' at {datetime.now()}\\n\")\n",
    "        webbrowser.open(f\"https://www.google.com/search?q={topic}\")\n",
    "        return f\"Researching '{topic}'. Notes saved.\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# EXECUTOR\n",
    "# ==================================================\n",
    "class Executor:\n",
    "    def __init__(self):\n",
    "        self.tools = Tools()\n",
    "\n",
    "    def execute(self, intent, params, memory, voice):\n",
    "        try:\n",
    "            if intent == \"OPEN_APP\":\n",
    "                return self.tools.open_app(params.get(\"app_names\", []))\n",
    "            if intent == \"OPEN_YOUTUBE\":\n",
    "                return self.tools.open_youtube()\n",
    "            if intent == \"PLAY_YOUTUBE\":\n",
    "                query = params.get(\"query\", \"\")\n",
    "                memory.update_context(\"last_topic\", query)\n",
    "                return self.tools.play_youtube(query)\n",
    "            if intent == \"PLAY_NEXT\":\n",
    "                last = memory.get_context(\"last_topic\")\n",
    "                return self.tools.play_next(last)\n",
    "            if intent == \"KNOWLEDGE\":\n",
    "                return self.tools.knowledge(params.get(\"topic\", \"\"), voice)\n",
    "            if intent == \"BATTERY_STATUS\":\n",
    "                return self.tools.detailed_battery_status()\n",
    "            if intent == \"SYSTEM_STATUS\":\n",
    "                return self.tools.system_status()\n",
    "            if intent == \"RESEARCH\":\n",
    "                return self.tools.research(params.get(\"topic\", \"\"), voice)\n",
    "            if intent == \"MEMORY_STATUS\":\n",
    "                recent = memory.get_recent_commands(6)\n",
    "                last = memory.get_context(\"last_action\")\n",
    "                response = \"Recent commands:\\n\" + \"\\n\".join(f\"- {c}\" for c in recent)\n",
    "                if last:\n",
    "                    response += f\"\\nLast action: {last}\"\n",
    "                return response or \"No history.\"\n",
    "            return \"Command executed.\"\n",
    "        except Exception as e:\n",
    "            voice.speak(\"Action failed. Trying fallback.\")\n",
    "            return f\"Fallback result: {str(e)}\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# CRITIC AGENT\n",
    "# ==================================================\n",
    "class Critic:\n",
    "    def evaluate(self, step, result):\n",
    "        if ollama:\n",
    "            prompt = f\"Evaluate step '{step}' with result '{result}'. Success? JSON: {{'success': true/false, 'feedback': '...' }}\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                out = json.loads(response['message']['content'])\n",
    "                return out['success'], out['feedback']\n",
    "            except:\n",
    "                pass\n",
    "        return True, \"Assumed good.\"\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# DASHBOARD\n",
    "# ==================================================\n",
    "class Dashboard:\n",
    "    def __init__(self, friday):\n",
    "        self.friday = friday\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"FRIDAY - Agentic Assistant\")\n",
    "        self.root.geometry(\"900x650\")\n",
    "        self.root.configure(bg=\"#1e1e1e\")\n",
    "\n",
    "        tk.Label(self.root, text=\"FRIDAY\", font=(\"Arial\", 20, \"bold\"), fg=\"#00ffcc\", bg=\"#1e1e1e\").pack(pady=15)\n",
    "        self.status = tk.Label(self.root, text=\"Status: Booting...\", fg=\"yellow\", bg=\"#1e1e1e\", font=(\"Arial\", 12))\n",
    "        self.status.pack()\n",
    "\n",
    "        self.logs = scrolledtext.ScrolledText(self.root, height=22, bg=\"#2d2d2d\", fg=\"white\", font=(\"Consolas\", 10))\n",
    "        self.logs.pack(padx=15, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        btn_frame = tk.Frame(self.root, bg=\"#1e1e1e\")\n",
    "        btn_frame.pack(pady=10)\n",
    "        tk.Button(btn_frame, text=\"Upload Document\", command=self.upload, bg=\"#333\", fg=\"white\", width=15).grid(row=0, column=0, padx=15)\n",
    "        tk.Button(btn_frame, text=\"View Memory\", command=self.view_memory, bg=\"#333\", fg=\"white\", width=15).grid(row=0, column=1, padx=15)\n",
    "\n",
    "    def log(self, text):\n",
    "        self.logs.insert(tk.END, f\"{datetime.now().strftime('%H:%M:%S')} | {text}\\n\")\n",
    "        self.logs.see(tk.END)\n",
    "\n",
    "    def upload(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Documents\", \"*.pdf *.docx *.txt\")])\n",
    "        if path:\n",
    "            self.friday.process_document(path)\n",
    "\n",
    "    def view_memory(self):\n",
    "        try:\n",
    "            with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            messagebox.showinfo(\"Memory\", content[:4000] + (\"\\n...\" if len(content) > 4000 else \"\"))\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "    def update(self):\n",
    "        self.root.update_idletasks()\n",
    "        self.root.update()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# REASONING ENGINE (FULL MULTI-STAGE WITH DAG + NEW FEATURES)\n",
    "# ==================================================\n",
    "class ReasoningEngine:\n",
    "    def __init__(self, voice, memory, executor):\n",
    "        self.voice = voice\n",
    "        self.memory = memory\n",
    "        self.executor = executor\n",
    "\n",
    "    def think(self, command):\n",
    "        self.voice.speak(\"Reasoning through the problem\")\n",
    "        if ollama:\n",
    "            prompt = f\"Think step-by-step about this user command: '{command}'. Provide a clear reasoning trace.\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                reasoning = response['message']['content']\n",
    "            except:\n",
    "                reasoning = \"Analyzing user objective\"\n",
    "        else:\n",
    "            reasoning = \"Analyzing user objective\"\n",
    "        self.voice.speak(reasoning)\n",
    "        return reasoning\n",
    "\n",
    "    def plan(self, command):\n",
    "        self.voice.speak(\"Goal → task decomposition\")\n",
    "        if ollama:\n",
    "            prompt = f\"Decompose this goal into sub-tasks with dependencies as JSON DAG: '{{ \\\"tasks\\\": [{{\\\"id\\\": 1, \\\"description\\\": \\\"step1\\\", \\\"dependencies\\\": []}}, {{ \\\"id\\\": 2, \\\"description\\\": \\\"step2\\\", \\\"dependencies\\\": [1]}} ] }}' for '{command}'\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                dag = json.loads(response['message']['content'])\n",
    "            except:\n",
    "                dag = {\"tasks\": [{\"id\": 1, \"description\": command, \"dependencies\": []}]}\n",
    "        else:\n",
    "            dag = {\"tasks\": [{\"id\": 1, \"description\": command, \"dependencies\": []}]}\n",
    "        self.voice.speak(\"Sub-task dependency handling (DAG)\")\n",
    "        return dag\n",
    "\n",
    "    def execute_dag(self, dag, intent, params):\n",
    "        self.voice.speak(\"Self-driven execution\")\n",
    "        task_map = {t['id']: t for t in dag.get('tasks', [])}\n",
    "        completed = set()\n",
    "        results = {}\n",
    "        while len(completed) < len(task_map):\n",
    "            executed = False\n",
    "            for tid, task in task_map.items():\n",
    "                if tid in completed:\n",
    "                    continue\n",
    "                deps = task.get('dependencies', [])\n",
    "                if all(d in completed for d in deps):\n",
    "                    self.voice.speak(f\"Executing sub-task {tid}: {task['description']}\")\n",
    "                    result = self.executor.execute(intent, params, self.memory, self.voice)\n",
    "                    results[tid] = result\n",
    "                    completed.add(tid)\n",
    "                    executed = True\n",
    "                    break\n",
    "            if not executed:\n",
    "                self.voice.speak(\"Dependency cycle detected or no progress. Aborting.\")\n",
    "                break\n",
    "        return results, task_map  # ← Return task_map too\n",
    "\n",
    "    def reflect(self, command, result):\n",
    "        self.voice.speak(\"Listening\")\n",
    "        if ollama:\n",
    "            prompt = f\"Reflect on command '{command}' with result '{result}'. What went well? What could be improved?\"\n",
    "            try:\n",
    "                response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "                reflection = response['message']['content']\n",
    "            except:\n",
    "                reflection = \"Action completed\"\n",
    "        else:\n",
    "            reflection = \"Action completed\"\n",
    "        self.voice.speak(reflection)\n",
    "        return reflection\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# FRIDAY CORE - FULL AGENTIC COGNITION\n",
    "# ==================================================\n",
    "class FRIDAY:\n",
    "    def __init__(self):\n",
    "        self.voice = VoiceEngine()\n",
    "        self.memory = MemoryEngine()\n",
    "        self.intent_engine = IntentEngine()\n",
    "        self.executor = Executor()\n",
    "        self.reasoning = ReasoningEngine(self.voice, self.memory, self.executor)\n",
    "        self.critic = Critic()\n",
    "        self.dashboard = Dashboard(self)\n",
    "        self.autonomous = False\n",
    "        self.command_mode = False\n",
    "\n",
    "    def authenticate(self):\n",
    "        self.voice.speak(\"Authentication required.\")\n",
    "        self.dashboard.log(\"Authentication started\")\n",
    "        self.dashboard.status.config(text=\"Status: Authenticating...\", fg=\"orange\")\n",
    "\n",
    "        while True:\n",
    "            mode = input(\"\\nPress 'v' for Voice or 't' for Text password: \").lower().strip()\n",
    "            if mode == 'v':\n",
    "                self.voice.speak(\"Say your password.\")\n",
    "                for _ in range(3):\n",
    "                    said = self.voice.listen_once()\n",
    "                    if said.strip() == PASSWORD.lower():\n",
    "                        self.voice.speak(\"Access granted. FRIDAY online.\")\n",
    "                        self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                        return True\n",
    "                    self.voice.speak(\"Incorrect.\")\n",
    "                return False\n",
    "            elif mode == 't':\n",
    "                typed = getpass.getpass(\"Enter password: \")\n",
    "                if typed == PASSWORD:\n",
    "                    self.voice.speak(\"Access granted. FRIDAY online.\")\n",
    "                    self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                    return True\n",
    "                print(\"Wrong.\")\n",
    "                for _ in range(2):\n",
    "                    typed = getpass.getpass(\"Try again: \")\n",
    "                    if typed == PASSWORD:\n",
    "                        self.voice.speak(\"Access granted.\")\n",
    "                        self.dashboard.status.config(text=\"Status: Online\", fg=\"lime\")\n",
    "                        return True\n",
    "                    print(\"Wrong.\")\n",
    "                return False\n",
    "\n",
    "    def process_document(self, path):\n",
    "        self.dashboard.log(f\"Uploaded: {os.path.basename(path)}\")\n",
    "        self.voice.speak(\"Document received.\")\n",
    "\n",
    "    def run(self):\n",
    "        if not self.authenticate():\n",
    "            return\n",
    "\n",
    "        self.dashboard.log(\"FRIDAY activated with multi-stage cognition\")\n",
    "        self.voice.speak(\"Autonomous multi-stage agentic cognition online.\")\n",
    "\n",
    "        while True:\n",
    "            self.dashboard.update()\n",
    "\n",
    "            mode = input(\"\\nPress 'v' for Voice, 't' for Text, 'q' to quit: \").lower().strip()\n",
    "            if mode == 'q':\n",
    "                self.voice.speak(\"Shutting down. Goodbye.\")\n",
    "                break\n",
    "            elif mode == 'v':\n",
    "                command = self.voice.continuous_listen()\n",
    "            elif mode == 't':\n",
    "                command = input(\"You (text): \").strip()\n",
    "            else:\n",
    "                print(\"Use v, t, or q.\")\n",
    "                continue\n",
    "\n",
    "            if not command:\n",
    "                continue\n",
    "\n",
    "            if command == \"command mode activate\":\n",
    "                if ollama is None:\n",
    "                    self.voice.speak(\"Ollama is not available.\")\n",
    "                    continue\n",
    "                self.command_mode = True\n",
    "                self.voice.speak(\"Command mode activated.\")\n",
    "                self.dashboard.log(\"Command mode activated.\")\n",
    "                continue\n",
    "            elif command == \"exit command mode\":\n",
    "                if self.command_mode:\n",
    "                    self.command_mode = False\n",
    "                    self.voice.speak(\"Command mode deactivated.\")\n",
    "                    self.dashboard.log(\"Command mode deactivated.\")\n",
    "                continue\n",
    "            elif self.command_mode:\n",
    "                self.dashboard.log(f\"You: {command}\")\n",
    "                self.memory.data[\"chatbot_history\"].append({\"role\": \"user\", \"content\": command})\n",
    "                try:\n",
    "                    response = ollama.chat(model='llama3', messages=self.memory.data[\"chatbot_history\"])\n",
    "                    assistant_reply = response['message']['content']\n",
    "                    self.memory.data[\"chatbot_history\"].append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "                    self.memory.save()\n",
    "                    self.voice.speak(assistant_reply)\n",
    "                    self.dashboard.log(f\"FRIDAY: {assistant_reply}\")\n",
    "                    self.memory.store_conversation(command, assistant_reply)\n",
    "                except Exception as e:\n",
    "                    self.voice.speak(\"Error in command mode.\")\n",
    "                    print(e)\n",
    "                continue\n",
    "\n",
    "            self.dashboard.log(f\"You: {command}\")\n",
    "\n",
    "            history = self.memory.data[\"short\"]\n",
    "            context = self.memory.data[\"context\"]\n",
    "\n",
    "            # Intent + Confidence + Explanation\n",
    "            intent, params, confidence, explanation = self.intent_engine.analyze(command, history, context)\n",
    "            self.dashboard.log(f\"Intent identified as: {intent}\")\n",
    "            self.voice.speak(f\"Intent identified as {intent}\")\n",
    "\n",
    "            if confidence < 0.7:\n",
    "                self.voice.speak(\"Low confidence. Clarifying.\")\n",
    "                clarification = self.voice.listen_once() or input(\"Clarify: \")\n",
    "                command += \" \" + clarification\n",
    "                intent, params, confidence, explanation = self.intent_engine.analyze(command, history, context)\n",
    "\n",
    "            # Multi-Stage Reasoning\n",
    "            self.dashboard.log(\"REASONING: Analyzing user objective\")\n",
    "            self.voice.speak(\"Analyzing user objective\")\n",
    "            think = self.reasoning.think(command)\n",
    "            self.dashboard.log(f\"REASONING: {think}\")\n",
    "\n",
    "            self.dashboard.log(\"REASONING: Selecting best available knowledge source\")\n",
    "            self.voice.speak(\"Selecting best available knowledge source\")\n",
    "            dag = self.reasoning.plan(command)\n",
    "            self.dashboard.log(f\"REASONING: Preparing fallback strategy if needed\")\n",
    "            self.voice.speak(\"Preparing fallback strategy if needed\")\n",
    "\n",
    "            # Action → Outcome → Evaluation loop with failure detection\n",
    "            self.dashboard.log(\"Action → Outcome → Evaluation loop\")\n",
    "            self.voice.speak(\"Action → Outcome → Evaluation loop\")\n",
    "            results, task_map = self.reasoning.execute_dag(dag, intent, params)  # ← Now receives task_map\n",
    "\n",
    "            for tid, result in results.items():\n",
    "                step_description = task_map.get(tid, {}).get('description', 'Unknown step')\n",
    "                success, feedback = self.critic.evaluate(step_description, result)\n",
    "                self.dashboard.log(f\"Evaluation: {'Success' if success else 'Failed'} - {feedback}\")\n",
    "\n",
    "                if not success:\n",
    "                    self.voice.speak(\"Failure detection + alternative strategy\")\n",
    "                    alt_prompt = f\"Alternative strategy for failed task {tid}: {feedback}\"\n",
    "                    alt_dag = self.reasoning.plan(alt_prompt)\n",
    "                    alt_results, _ = self.reasoning.execute_dag(alt_dag, intent, params)\n",
    "                    results[tid] = list(alt_results.values())[0] if alt_results else \"Alternative failed\"\n",
    "\n",
    "            final_result = json.dumps(results, indent=2)\n",
    "            self.dashboard.log(f\"FRIDAY: {final_result}\")\n",
    "            self.voice.speak(final_result)\n",
    "\n",
    "            self.memory.update_context(\"last_action\", command)\n",
    "            self.memory.store_conversation(command, final_result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FRIDAY().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
